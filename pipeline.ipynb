{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import LeafSLA # custom functions from LeafSLA.py – must be in same directory as this script (pipeline.ipynb), otherwise you have to use os.chdir to help it find the script\n",
    "\n",
    "os.chdir(\"/Users/kericlamb/Documents/Work MacBook/Research/protocols/phenotyping_drought/leaf_lobing/\") # directory with the file ./LeafSLA.py in it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable definitions needed for both pipelines \n",
    "img_folder = \"mim_SLA\" # folder name that has images to process (within the current working directory, e.g., /Users/kericlamb/.../leaf_lobing/photos)\n",
    "sq_size = 1 # size of the square (one side) in the image used as the standard -- I've been using SH=1 and LB=2 (?)\n",
    "\n",
    "# for SAM pipeline\n",
    "model_type = \"vit_b\"  # \"vit_h\" (best), \"vit_l\" (medium), \"vit_b\" (smallest)\n",
    "checkpoint = \"~/Documents/SAM/sam_vit_b_01ec64.pth\"\n",
    "bbox_multiplier = 4 # 2 for Lynn; 4 for Stacy... mess around with it. has to do with size of the red square more than anything\n",
    "leaf_position = \"above\" # where leaf is relative to the red square\n",
    "perspective_shift = False # for SH, False is best. for LB 2023 images, True is best\n",
    "\n",
    "# for algorithmic pipeline\n",
    "saturation = 50 # saturation level. 50 for Stacy H., 70 for Lynn B.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the SAM Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: 20240702_190448 - 96 %   \r"
     ]
    }
   ],
   "source": [
    "# read in images and create lists of the image names sans extension (img_names) and image full paths to the working directory (img_list)\n",
    "img_list, img_names = LeafSLA.img_import(img_folder=img_folder, folders=False)\n",
    "df, area_df = LeafSLA.new_data()\n",
    "\n",
    "# run a for-loop for all images in the specified img_folder\n",
    "for i in range(len(img_names)):\n",
    "    # print only every ten images\n",
    "    if i % 1 == 0: \n",
    "        perc = int((i/len(img_names))*100)\n",
    "        print(f'Processing image: {img_names[i]} - {perc} %   ', end='\\r')\n",
    "    \n",
    "    try: \n",
    "        # reads in image and finds loose bounding boxes for the leaf and red box using color thresholding and saves an image copy to ./bbox path\n",
    "        leaf_array, box_array = LeafSLA.setup_image(img_src=img_list[i], img_folder=img_folder, img_name=img_names[i], color_ranges=LeafSLA.color_thresher(), \n",
    "                                                    sq_size=sq_size, leaf_position=leaf_position, bbox_multiplier=bbox_multiplier)\n",
    "\n",
    "        # applies SAM – does not return an object but saves copy to the ./threshold path\n",
    "        LeafSLA.SAM_image(img_src=img_list[i], img_folder=img_folder, img_name=img_names[i], leaf_array=leaf_array, box_array=box_array, model_type=\"vit_b\", \n",
    "                        checkpoint=\"./SAM/models/sam_vit_b_01ec64.pth\", device=\"mps\")\n",
    "\n",
    "        # applies minor blurring and edge smoothing (degree of which is controlled by erode and sigma (these are hidden but can be added to the function below))\n",
    "        binary_image = LeafSLA.image_repair(img_folder=img_folder, img_name=img_names[i])\n",
    "\n",
    "        # corrects for perspective using the red square and saves a copy to ./perspective path\n",
    "        if perspective_shift == True:\n",
    "            binary_image = LeafSLA.perspective_correction(binary_image, img_folder, img_name=img_names[i])\n",
    "\n",
    "        # measures all relevant phenotypes and saves a copy to ./processed path\n",
    "        df, area_df = LeafSLA.contour_measurement(img_src=img_list[i], img_folder=img_folder, img_name=img_names[i], image=binary_image, sq_size=sq_size,\n",
    "                                                df=df, area_df=area_df, method=\"SAM\")\n",
    "    except Exception as e: \n",
    "        print(f\"{img_names[i]} had the error: {e}\")\n",
    "        print(\"\") # prevents multiple statement prints per line\n",
    "    \n",
    "# save all relevant data for each image AFTER all images have been processed\n",
    "df.to_csv('./data/{0}_metadata.csv'.format(img_folder), index=False)\n",
    "area_df.to_csv('./data/{0}_measurements_sam.csv'.format(img_folder), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Naive Pipeline\n",
    "###### This pipe is more prone to error on difficult images, but works decently on simpler images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in images and create lists of the image names sans extension (img_names) and image full paths to the working directory (img_list)\n",
    "img_list, img_names = LeafSLA.img_import(img_folder=img_folder, folders=False)\n",
    "df, area_df = LeafSLA.new_data()\n",
    "\n",
    "# run a for-loop for all images in the specified img_folder\n",
    "for i in range(len(img_names)):\n",
    "    # print only every ten images\n",
    "    if i % 1 == 0: \n",
    "        perc = int((i/len(img_names))*100)\n",
    "        print(f'Processing image: {img_names[i]} - {perc} %   ', end='\\r')\n",
    "\n",
    "    # this pipeline is more prone to error, so nesting in try/except loop that will print error if things go south\n",
    "    try: \n",
    "        # read in image and apply naïve pipeline\n",
    "        LeafSLA.algo_pipeline(img_src=img_list[i], img_folder=img_folder, img_name=img_names[i], saturation=saturation)\n",
    "\n",
    "        # applies minor blurring and edge smoothing (degree of which is controlled by erode and sigma (these are hidden but can be added to the function below))\n",
    "        binary_image = LeafSLA.image_repair(img_folder=img_folder, img_name=img_names[i])\n",
    "\n",
    "        # corrects for perspective using the red square and saves a copy to ./perspective path\n",
    "        corrected_image = LeafSLA.perspective_correction(binary_image, img_folder, img_name=img_names[i])\n",
    "\n",
    "        # measures all relevant phenotypes and saves a copy to ./processed path\n",
    "        df, area_df = LeafSLA.contour_measurement(img_src=img_list[i], img_folder=img_folder, img_name=img_names[1], image=corrected_image, sq_size=sq_size,\n",
    "                                                  df=df, area_df=area_df)\n",
    "    except Exception as e: \n",
    "        print(f\"{img_names[i]} had the error: {e}\")\n",
    "        print(\"\") # prevents multiple statement prints per line\n",
    "\n",
    "# save all relevant data for each image AFTER all images have been processed\n",
    "df.to_csv('./data/{0}_metadata.csv'.format(img_folder), index=False)\n",
    "area_df.to_csv('./data/{0}_measurements_sam.csv'.format(img_folder), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
